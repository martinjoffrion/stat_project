---
title: "Statistiques - Modèles linéaires"
author: "JOFFRION Martin & KNOBLOCH Adrien"
date: "2023 - 2024"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.align = 'center')
```

## Question 1

```{r}
# imports
library(car)

setwd("C:/ENSAT/stat_project")
data <- read.csv("dataProjet_2024.csv", header = T, sep = ",")

# filtrer dataset
data_quercus <- data[data$recherche_esp_lb_nom_plantae == "Quercus L., 1753",]

# modèle ANOVA
modAnovRegQuad2_Querc_BC <- lm(I(log10(DBH))~alti+I(alti^2)+releve,data=data_quercus) 
modAnov_resStand <- rstandard(modAnovRegQuad2_Querc_BC)

### Hypothèse 1 : loi gaussienne des erreurs
bks <- seq(-6,6,0.1)
qqPlot(modAnov_resStand,distribution="norm",mean=0,sd=1,line="none")
hist(modAnov_resStand, probability=T, breaks=bks)
lines(bks,dnorm(bks,0,1),col="blue")

### Hypothèse 2 : indépendance des erreurs

vecIndObs <- as.numeric(rownames(modAnovRegQuad2_Querc_BC$model))
boxplot(modAnov_resStand~data_quercus$Status[vecIndObs],xlab="", 
        ylab="Résidu standardisé",las=2,range=0)
abline(h=0,lty="dashed")

### Hypothèse 3 : homoscédasticité des erreurs

#SL-plot
plot(modAnovRegQuad2_Querc_BC,which=3,pch=3, add.smooth = FALSE) #Base du SL-plot pré-programmée dans R
abline(h=0.8,col=4,lwd=2) #Ligne horizontale attendue
lo <- loess(sqrt(abs(modAnov_resStand))~modAnovRegQuad2_Querc_BC$fitted.values) #Moyenne glissante des points
vFit <- sort(unique(modAnovRegQuad2_Querc_BC$fitted.values))
predLo <- predict(lo,vFit,se=TRUE)
lines(predLo$fit~vFit,col=2,lwd=2)
#Enveloppe de confiance autour de cette moyenne glissante :
nFit <- length(vFit); ICBonf <- qnorm(1-0.05/2/nFit)
lines(predLo$fit+ICBonf*predLo$se.fit~sort(
    unique(modAnovRegQuad2_Querc_BC$fitted.values)
  ),col=2,lwd=2,lty="dashed")
lines(predLo$fit-ICBonf*predLo$se.fit~sort(
    unique(modAnovRegQuad2_Querc_BC$fitted.values)
  ),col=2,lwd=2,lty="dashed")

```

-   Hypothèse 1 : loi gaussienne des erreurs :

La forme slalomée de la répartition des résidus sur le qqplot indique un potentiel défault de Kurtosis, confirmé sur l'histogramme de répartition. Notre jeu de donnée souffre ainsi d'un excès de Kurtosis, acceptable au vu de la robustesse du modèle gaussien.

-   Hypothèse 2 : indépendance des erreurs :

Notre modèle est déjà filtré sur une espèce, et l'ANOVA intègre les variables relevé et altitude, la seule variable encore susceptible de générer une dépendance des résidus est le statut, à savoir l'état de l'arbre au moment du prélèvement.

Le boxplot démontre l'absence de biais sur les résidus, et donc l'indépendance des individus par rapport à la variable statut.

-   Hypothèse 3 : homoscédasticité des erreurs :

Sur le SL-plot, la moyenne lissée (courbe rouge pleine) des résidus standardisés est presque confondue avec la moyenne théorique attendue (courbe bleue), preuve de l'homoscédasticité des erreurs.

Le modèle \*modAnovRegQuad2_Querc_BC3 avec effet de relevé et effet quadratique de l'altitude valide donc toutes les hypothèses du modèle linéaire.

## Question 2

```{r}
# Define model 
modAnova <- lm(DBH~0+releve+recherche_esp_lb_nom_plantae,data=data)
modAnov_resStand <- rstandard(modAnova)

### Hypothèse 1 : loi gaussienne des erreurs
bks <- seq(-7,7,0.1)
qqPlot(modAnov_resStand,distribution="norm",mean=0,sd=1,line="none")
hist(modAnov_resStand, probability=T, breaks=bks)
lines(bks,dnorm(bks,0,1),col="blue")

### Hypothèse 2 : indépendance des erreurs
vecIndObs <- as.numeric(rownames(modAnova$model))
boxplot(modAnov_resStand~data$recherche_esp_lb_nom_plantae[vecIndObs],xlab="", 
        ylab="Résidu standardisé",las=2,range=0)
abline(h=0,lty="dashed")

### Hypothèse 3 : homoscédasticité des erreurs
#SL-plot
plot(modAnova,which=3,pch=3, add.smooth = FALSE) #Base du SL-plot pré-programmée dans R
abline(h=0.8,col=4,lwd=2) #Ligne horizontale attendue
lo <- loess(sqrt(abs(modAnov_resStand))~modAnova$fitted.values) #Moyenne glissante des points
vFit <- sort(unique(modAnova$fitted.values))
predLo <- predict(lo,vFit,se=TRUE)
lines(predLo$fit~vFit,col=2,lwd=2)
#Enveloppe de confiance autour de cette moyenne glissante :
nFit <- length(vFit); ICBonf <- qnorm(1-0.05/2/nFit)
lines(predLo$fit+ICBonf*predLo$se.fit~sort(
    unique(modAnova$fitted.values)
  ),col=2,lwd=2,lty="dashed")
lines(predLo$fit-ICBonf*predLo$se.fit~sort(
    unique(modAnova$fitted.values)
  ),col=2,lwd=2,lty="dashed")


### Analyse des sorties
  # estimation des intervalles de confiance
summary(modAnova)$coefficients
tabConfInt <- confint(modAnova,level=0.95)
par(mfrow=c(1,2))

x <- barplot(summary(modAnova)$coefficients[,1],las=2)
arrows(x0 = x, y0= tabConfInt[,1],
  y1=tabConfInt[,2], code=3,angle=90,
  length=0.05)

  # test de significativité selon une sous-population de référence
    # Définition d'une sous-population de référence, ici BLO_11 
data$releve <- relevel(as.factor(data$releve),ref="BLO_1")

    # Reformulation du modèle ANOVA :
modAnovaDif <- lm(DBH~releve+recherche_esp_lb_nom_plantae,data=data)
summary(modAnovaDif)$coefficients

summary(modAnova)$coefficients
summary(modAnovaDif)$coefficients
tabConfInt <- confint(modAnovaDif,level=0.95)

  # R²
x <- boxplot(DBH~releve,data=data,range=0,las=2,xlab="",cex.axis=0.5)
vCoef <- modAnova$coefficients[
    match(x$names,gsub("releve","",names(modAnova$coefficients)))]
points(1:length(vCoef),rep(mean(data$DBH,na.rm=TRUE),length(vCoef)),pch=21,bg=4)
points(1:length(vCoef),
  modAnova$coefficients[
    match(x$names,gsub("releve","",names(modAnova$coefficients)))],
  pch=21,bg=2)
```

-   Hypothèse 1 : loi gaussienne des erreurs :

A nouveau, la forme slalomée de la répartition des résidus sur le qqplot indique un potentiel défault de Kurtosis, aditionné à un légère asymétrie, confirmés sur l'histogramme de répartition. Notre jeu de donnée souffre d'un excès de Kurtosis et d'une légère asymétrie à gauche.

-   Hypothèse 2 : indépendance des erreurs :

Notre modèle n'est plus filtré sur une espèce, mais l'ANOVA intègre toutes les variables potentiellement sources de dépendance des erreurs. Ainsi, les résidus ont un biais nul quant à la variable espèce, comme prouvé sur le boxplot.

-   Hypothèse 3 : homoscédasticité des erreurs :

Sur le SL-plot, la moyenne lissée (courbe rouge pleine) des résidus standardisés s'éloigne fortement de la moyenne théorique attendue (courbe bleue). Les résidus ont une trop forte variance pour les relevés à faible diamètre et à fort diamètre moyen.


Inclure la variable espèce dans l'ANOVA n'est donc pas une solution pour combler l'influence des espèces. Le modèle ne valide pas complètement les hypothèses de départ. Au vu de la robustesse du test ANOVA, nous continuons l'analyse, et comme attendu, les résultats sont très médiocres. 

Sur le boxplot final, on observe ainsi des moyennes empiriques de sous échantillons (points rouges) plus "éloignées" des sous échantillons que la moyenne empirique globlabe (point bleu), symptome de l'échec du modèle.

## Question 3

```{r}
### Création d'une colonne d'appartenance à un triangle
data_quercus$triangle[data_quercus$releve == 'BLO_12'|
                 data_quercus$releve == 'BLO_13'|
                 data_quercus$releve == 'BLO_17'] <- 'TR_1'

data_quercus$triangle[data_quercus$releve == 'BLO_1'|
                 data_quercus$releve == 'BLO_4'|
                 data_quercus$releve == 'BLO_9'] <- 'TR_2'

data_quercus$triangle[data_quercus$releve == 'BLO_21'|
                 data_quercus$releve == 'BLO_24'|
                 data_quercus$releve == 'BLO_27'] <- 'TR_3'

### Plot des triangles
plot(lati~long, data=data_quercus,xlab="Longitude WGS84",ylab="Latitude WGS84",pch=3)
triangle <-  unique(data_quercus$triangle)
col_pal <- c('red','green','blue')
for (i in 1:length(triangle))
  {
  data_temp <- data_quercus[data_quercus$triangle == triangle[i],]

  coorPla <- sapply(unique(data_temp$releve),function(idPla){
   vIndPla <- which(data_temp$releve==idPla)
   latiPla <- mean(data_temp$lati[vIndPla],na.rm=TRUE)
   longPla <- mean(data_temp$long[vIndPla],na.rm=TRUE)
   return(c(longPla,latiPla))
  })
  polygon(coorPla[1,],coorPla[2,],col = col_pal[i] )
  text(mean(coorPla[1,],na.rm=TRUE),mean(coorPla[2,],na.rm=TRUE),labels = triangle[i])
}

coorPla <- sapply(unique(data_quercus$releve),function(idPla){
 vIndPla <- which(data_quercus$releve==idPla)
 latiPla <- mean(data_quercus$lati[vIndPla],na.rm=TRUE)
 longPla <- mean(data_quercus$long[vIndPla],na.rm=TRUE)
 return(c(longPla,latiPla))
})
text(coorPla[1,],coorPla[2,],colnames(coorPla),col=4,cex=0.5,font=2)


### Définition du moèle Triangle
modAnovaTriangle <- lm(DBH~0+triangle,data=data_quercus)
modAnov_resStand <- rstandard(modAnovaTriangle)

### Hypothèse 1 : loi gaussienne des erreurs
bks <- seq(-3,8,0.1)
qqPlot(modAnov_resStand,distribution="norm",mean=0,sd=1,line="none")
hist(modAnov_resStand, probability=T, breaks=bks)
lines(bks,dnorm(bks,0,1),col="blue")

### Hypothèse 2 : indépendance des erreurs
vecIndObs <- as.numeric(rownames(modAnovaTriangle$model))
boxplot(modAnov_resStand~data_quercus$releve[vecIndObs],xlab="", 
        ylab="Residu standardise",las=2,range=0)
abline(h=0,lty="dashed")

### Hypothèse 3 : homoscédasticité des erreurs
#SL-plot
plot(modAnovaTriangle,which=3,pch=3, add.smooth = FALSE) #Base du SL-plot pré-programmée dans R
abline(h=0.8,col=4,lwd=2) #Ligne horizontale attendue
lo <- loess(sqrt(abs(modAnov_resStand))~modAnovaTriangle$fitted.values) #Moyenne glissante des points
vFit <- sort(unique(modAnovaTriangle$fitted.values))
predLo <- predict(lo,vFit,se=TRUE)
lines(predLo$fit~vFit,col=2,lwd=2)
#Enveloppe de confiance autour de cette moyenne glissante :
nFit <- length(vFit); ICBonf <- qnorm(1-0.05/2/nFit)
lines(predLo$fit+ICBonf*predLo$se.fit~sort(
    unique(modAnovaTriangle$fitted.values)
  ),col=2,lwd=2,lty="dashed")
lines(predLo$fit-ICBonf*predLo$se.fit~sort(
    unique(modAnovaTriangle$fitted.values)
  ),col=2,lwd=2,lty="dashed")

### F test : comparaison avec un modèle sans regroupemment en triangle des sous-populations 
modAnovaReleve <- lm(DBH~0+releve,data=data_quercus)
anova(modAnovaTriangle, modAnovaReleve)
```

-   Hypothèse 1 : loi gaussienne des erreurs :

A nouveau, la forme slalomée de la répartition des résidus sur le qqplot indique un potentiel défault de Kurtosis important, aditionné à un asymétrie marquée, confirmés sur l'histogramme de répartition. Notre jeu de donnée souffre d'un excès de Kurtosis et d'une forte asymétrie à gauche, invalidant l'hypothèse de normalité.

-   Hypothèse 2 : indépendance des erreurs :

Notre modèle filtré intègre toutes les variables potentiellement sources de dépendances des erreurs sauf celle du relevé. Nous allons donc tester la dépendance des résidus concernant cette variable. 

Nous observons sur le boxplot obtenu de légers biais, notamment pour les relevés 12, 13 et 17 (triangle 1). L'indépendance n'est donc pas pleinement satisfaisante.

-   Hypothèse 3 : homoscédasticité des erreurs :

Sur le SL-plot, nous constatons une variance trop faible pour les relevés à fort diamètre moyen. La moyenne lissée reste toutefois proche de la moyenne théorique. 

Les résultats du test emboîté pour ce niveau d'agrégation ne sont pas concluants. Comparé au modèle complexe de relevé, le facteur F est très important (239.87) et la p-value très faible (<2.2e-16). La probabilité que le modèle de relevé augmente la valeur du coefficient de corrélation par rapport à notre modèle à triangle est très élevée, de l'odre de 99%.

La fusion des sous populations n'est donc pas efficace. Le modèle initial intégrant la variable relevé sans regroupement reste le plus cohérent.

## Question 4

```{r}
## Création d'une  variable 'dernière coupe massive' standardisée
vLogRel <- scale(coef(lm(lastLog~0+releve,data=data_quercus)))
rownames(vLogRel) <- sub("releve","",rownames(vLogRel))
data_quercus$LogRel <- vLogRel[
  match(data_quercus$releve,rownames(vLogRel)),1]
  
## Création d'un modèle mixte
modRegQuadLatRel_Querc_BC <- lm(
  I(log10(DBH))~alti+I(alti^2)+LogRel,data=data_quercus)
summary(modRegQuadLatRel_Querc_BC )

## Vérification des hypothèses
mod <- modRegQuadLatRel_Querc_BC
#DISTRIBUTION SYMETRIQUE
qqPlot(mod,distribution="norm",line="none")
#HOMOSCEDASTICITE
plot(mod,which=3,pch=3, add.smooth = FALSE)
#Ligne horizontale attendue
abline(h=0.8,col=4,lwd=2)
#Moyenne glissante
lo <- loess(
  sqrt(abs(rstandard(mod)))~mod$fitted.values) 
vFit <- sort(unique(mod$fitted.values))
predLo <- predict(lo,vFit,se=TRUE)
lines(predLo$fit~vFit,col=2,lwd=2)
#Enveloppe de confiance autour de cette moyenne glissante :
nFit <- length(vFit); ICBonf <- qnorm(1-0.05/2/nFit)
lines(predLo$fit+ICBonf*predLo$se.fit~vFit,col=2,lwd=2,lty="dashed")
lines(predLo$fit-ICBonf*predLo$se.fit~vFit,col=2,lwd=2,lty="dashed")
#INDEPENDANCE
x <- mod$model$LogRel
plot(mod$residuals~x)
abline(h=0,col=4)
#Moyenne glissante
lo <- loess(
 mod$residuals~x) 
vFit <- sort(unique(x))
predLo <- predict(lo,vFit,se=TRUE)
lines(predLo$fit~vFit,col=2,lwd=2)
#Enveloppe de confiance autour de cette moyenne glissante :
nFit <- length(vFit); ICBonf <- qnorm(1-0.05/2/nFit)
lines(predLo$fit+ICBonf*predLo$se.fit~vFit,col=2,lwd=2,lty="dashed")
lines(predLo$fit-ICBonf*predLo$se.fit~vFit,col=2,lwd=2,lty="dashed")
```

Comparé aux résultats obtenus avec la variable latitude, la variable *lasLog* (dernière coupe massive) explique bien mieux l'effet relevé. C'est notamment visible dans le Scale-Location plot, où la moyenne glissée suit presque parfaitement le moyenne théorique, à l'exception des individus aux forts diamètres. 

Toutefois, l'effet des relevés persiste, comme illustré dans le dernier graphique. 

La variable dernière coupe massive explique donc partiellement l'effet relevé.

## Question 5

```{r}
# Import
library(DHARMa)

# Sélection des individus avec cavité
data_quercus$cavPA <- (data_quercus$cav_basses_presence_cavites=="oui")

# Création du modèle linaire binomial généralisé
modBinCavPA <- glm(cavPA~alti+releve+DBH,
  data=data_quercus,

  family=binomial(link = "logit"))

# Vérification des hypothèses
residusTransfo <- simulateResiduals(modBinCavPA ,n=1000)
testUniformity(residusTransfo)
testCategorical(residusTransfo,modBinCavPA$model$releve)
testQuantiles(residusTransfo,predictor=modBinCavPA$model$alti)

# Résultats
summary(modBinCavPA)
confint(modBinCavPA)

# Calcul du R² de McFadden
mod_0 <- glm(cavPA~1,data=data_quercus,family=binomial(link="logit"))
R2_mcFadden <- 1-modBinCavPA$deviance/mod_0$deviance
sprintf('le R² de McFadden est de %f', R2_mcFadden)
```

En sortie du graphique qqplot, nous obtenons une p-value de 0.9887. L'hypothèse nulle est donc acceptée : la distribution des résidus est uniforme. 

En sortie du graphique testCategorical, nous obtenons une p-value de 0.9376. L'hypothèse nulle est donc acceptée : la distribution des résidus par relevé est uniforme.

En sortie du graphique testQuantiles, nous obtenons une p-value de 0.9946. L'hypothèse nulle est donc acceptée : la distribution des résidus est homogène

Les hypothèses du nouveau modèle sont ainsi vérifiées.

### Analyse des résultats
Comme le cas étudié dans le cours, l'altitude a un intervalle de confiance "centré" autour de 0, avec une p-value supérieure au seuil de confiance de 95% fixé. L'hypothèse nulle est donc vraissemblablement vérifiée : l'altitude n'a pas d'impact sur la formation des cavités.

Dans le cas du DBH, les résultats sont similaires : l'intervalle de confiance est proche et "centré" autour de 0, avec une p-value de 0.7 largement supérieure à 0.05. A nouveau, l'hypothèse nulle est donc vraissemblablement vérifiée : le DBH n'a pas d'impact sur la formation des cavités.

Pour affirmer ces résultats, nous avons calculé le R² de McFadden, afin d'évaluer le progrès apporté en terme de vraisemblance par notre modèle avec les covariables DBH et altitude. 

La valeur de R² obtenue est de 0.19, soit relativement faible. L'ajout des covariables DBH et altitude n'a donc pas significativement amélioré la qualité du modèle, confirmant ainsi les résultats obtenus précédemment. 
Dans le cours, le R² de McFadden obtenu avec un modèle avec altitude seulement était de 0.188, soit très légèrement inférieur à celui obtenu avec l'ajout du DBH, confirmant encore une fois le très faible impact du DBH sur le modèle.